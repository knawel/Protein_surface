{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "670991eb-37cd-44fc-9336-44c35d062fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.data import ProteinsDataset, AllVertices, ProteinRecord\n",
    "from src.nn_model import Amber_NN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "38f2c007-14b8-432a-8384-86f944893429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = torch.manual_seed(142)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ba7f95f6-41e1-42d0-b770-ef6e7c527bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "protein = [\"1FZW_B\", \"1GP2_BG\", \"2E7J_B\", \"2E89_A\", \"2EG5_E\", \"2NYZ_A\",\n",
    "           \"2OOR_A\", \"3AAA_AB\",\n",
    "           \"7FCT_A\", \"7MX9_A\", \"7N8G_A\", \"7QRR_A\", \"7WUG_145\"] \n",
    "# \"6BOY_BC\", <- left it for testing\n",
    "pd = AllVertices(protein)\n",
    "\n",
    "n_features = pd[0][0].shape[0]\n",
    "\n",
    "train_dataset, test_dataset = random_split(pd, [0.85, 0.15],\n",
    "             generator=torch.Generator().manual_seed(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2d192411-2e78-4717-be27-2fc18385c055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230080\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "print(len(pd))\n",
    "print(n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6eb055f9-9213-45f3-bd86-22412b13ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0c3e2485-220f-425c-aaf5-eedea5d72566",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_size, p = 0.1):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(p) \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc4(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class Amber_NN(nn.Module):\n",
    "\n",
    "    def __init__(self, nfeatures, nclasses):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(nfeatures, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, nclasses)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7eacc2f6-7693-45a2-bc7c-8c1f42b5e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-3\n",
    "batch_size = 128\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "model = NeuralNet(n_features, 3, 256).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8cb82ecd-6b0f-417e-ac6d-2c6793a70077",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.stack([train_dataset[333][0], train_dataset[235][0]], axis=0)\n",
    "X = X.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ba906973-125d-4415-be13-0ec5818296b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2d932387-8482-4160-a007-7c4ae5927535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            \n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9a8adc73-27c4-4109-a595-526bd12ede90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.077596  [  128/195568]\n",
      "loss: 0.933999  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 0.811236 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.853248  [  128/195568]\n",
      "loss: 0.927002  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.791923 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.839897  [  128/195568]\n",
      "loss: 0.850629  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.759220 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.815682  [  128/195568]\n",
      "loss: 0.838163  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 0.751968 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.799493  [  128/195568]\n",
      "loss: 0.831783  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.745294 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.801085  [  128/195568]\n",
      "loss: 0.832500  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.742281 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.791491  [  128/195568]\n",
      "loss: 0.827461  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.737518 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.801763  [  128/195568]\n",
      "loss: 0.805026  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.735439 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.795809  [  128/195568]\n",
      "loss: 0.824570  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.731348 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.793849  [  128/195568]\n",
      "loss: 0.784562  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.728651 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.798224  [  128/195568]\n",
      "loss: 0.813434  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.725671 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.768430  [  128/195568]\n",
      "loss: 0.835120  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.723100 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.806636  [  128/195568]\n",
      "loss: 0.794378  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.720360 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.806256  [  128/195568]\n",
      "loss: 0.810045  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.717680 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.788094  [  128/195568]\n",
      "loss: 0.798820  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.717326 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.786183  [  128/195568]\n",
      "loss: 0.766828  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.714709 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.784055  [  128/195568]\n",
      "loss: 0.783284  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.713108 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.767029  [  128/195568]\n",
      "loss: 0.758086  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.711722 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.786841  [  128/195568]\n",
      "loss: 0.785263  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.708392 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.752121  [  128/195568]\n",
      "loss: 0.772000  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.708881 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.757207  [  128/195568]\n",
      "loss: 0.757192  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.706953 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.771180  [  128/195568]\n",
      "loss: 0.752786  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.706106 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.776741  [  128/195568]\n",
      "loss: 0.769581  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.701683 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.750352  [  128/195568]\n",
      "loss: 0.772292  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.700218 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.780017  [  128/195568]\n",
      "loss: 0.772931  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.699461 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.757015  [  128/195568]\n",
      "loss: 0.767245  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 0.697879 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.738868  [  128/195568]\n",
      "loss: 0.735169  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.697319 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.745864  [  128/195568]\n",
      "loss: 0.770636  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.696186 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.750610  [  128/195568]\n",
      "loss: 0.707487  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.694392 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.714263  [  128/195568]\n",
      "loss: 0.738949  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.691913 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.726655  [  128/195568]\n",
      "loss: 0.780858  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.691074 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.742883  [  128/195568]\n",
      "loss: 0.761336  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.688785 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.718614  [  128/195568]\n",
      "loss: 0.711728  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.689620 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.716723  [  128/195568]\n",
      "loss: 0.746161  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 0.688121 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.720765  [  128/195568]\n",
      "loss: 0.729587  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.687425 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.714678  [  128/195568]\n",
      "loss: 0.734767  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.684002 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.711013  [  128/195568]\n",
      "loss: 0.716937  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.683567 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.754989  [  128/195568]\n",
      "loss: 0.723247  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.682688 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.692449  [  128/195568]\n",
      "loss: 0.730969  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.681802 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.677598  [  128/195568]\n",
      "loss: 0.725265  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.681397 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.670130  [  128/195568]\n",
      "loss: 0.709731  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.678543 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.690461  [  128/195568]\n",
      "loss: 0.715649  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.679269 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.685387  [  128/195568]\n",
      "loss: 0.727242  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 0.677272 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.694644  [  128/195568]\n",
      "loss: 0.691494  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.679111 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.709746  [  128/195568]\n",
      "loss: 0.680843  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.675957 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.667191  [  128/195568]\n",
      "loss: 0.711563  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.673998 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.679071  [  128/195568]\n",
      "loss: 0.684879  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 0.675452 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.690261  [  128/195568]\n",
      "loss: 0.688584  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 0.674035 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.677500  [  128/195568]\n",
      "loss: 0.690526  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.672386 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.688032  [  128/195568]\n",
      "loss: 0.684775  [128128/195568]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.674070 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8657578-acc5-4ffe-ab61-5ad6602af999",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a2cd8697-c197-4375-a63e-9ce8457a084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_for_paraview(filename, xyz_tensor, color_tensor, z_shift = 0):\n",
    "    \n",
    "    tosave = torch.cat([xyz_tensor, color_tensor[:,None]], dim=1)\n",
    "    qc = tosave.cpu().detach().numpy()\n",
    "    with open(filename, 'w') as iFile:\n",
    "        iFile.write(\"x,y,z,c\\n\")\n",
    "        for i in qc:\n",
    "            x,y,z,c = i\n",
    "            iFile.write(f'{x},{y},{z+z_shift},{c}\\n')\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4c42b336-a927-4300-bcad-19e97cb40623",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trial_pdb = \"6BOY_B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "665da8ae-7150-4267-b2cf-c947f302a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ProteinRecord(Trial_pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "dff67995-6dea-4c43-9e8b-1272b4296d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.f.to(device)\n",
    "p = data.p.to(device)\n",
    "y = data.y_aux.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "bcaba120-bf89-4cec-9919-d5e16d55dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(X)\n",
    "    pred_probab = nn.Softmax(dim=1)(logits)\n",
    "    y_pred = pred_probab.argmax(1)\n",
    "    # print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c7d94e4a-aa31-40a8-8ff6-fb58ed257d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_for_paraview(f\"predicted_{Trial_pdb}.csv\", p, y_pred)\n",
    "save_for_paraview(f\"real_{Trial_pdb}.csv\", p, y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6962aca6-1e0d-4c91-9720-4557ee8c126c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 1, 1, 1, 2, 2,\n",
       "        2, 2, 1, 1, 1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1,\n",
       "        1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[580:680]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
